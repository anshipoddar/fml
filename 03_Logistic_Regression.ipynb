{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression"
      ],
      "metadata": {
        "id": "GsBSX_FW2m1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Setup and Data Loading**\n",
        "\n",
        "**Imports**:\n",
        "\n",
        "- LogisticRegression from scikit-learn for modeling.\n",
        "\n",
        "- StandardScaler for feature standardization (critical for gradient-based optimization).\n",
        "\n",
        "- classification_report for evaluation.\n",
        "\n",
        "**Data Loading**:\n",
        "\n",
        "- Loads magic04.data with particle collision features.\n",
        "\n",
        "- Converts class labels to binary (1=Gamma, 0=Hadron)."
      ],
      "metadata": {
        "id": "H6k0xoUD3-aV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cehUV6QH2Rld"
      },
      "outputs": [],
      "source": [
        "# Setup and Data Loading\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "cols = [\"fLength\", \"fWidth\", \"fSize\", \"fConc\", \"fConcl\", \"fAsym\",\n",
        "        \"fM3Long\", \"fM3Trans\", \"fAlpha\", \"fDist\", \"class\"]\n",
        "df = pd.read_csv(\"magic04.data\", names=cols)\n",
        "df[\"class\"] = (df[\"class\"] == \"g\").astype(int)  # Binary: 1=Gamma, 0=Hadron"
      ],
      "metadata": {
        "id": "ww1mLypm2uxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Data Preparation**\n",
        "\n",
        "- **prepare_data() Function**:\n",
        "\n",
        "- - Standardizes features (StandardScaler) to ensure equal weighting in the logistic loss function.\n",
        "\n",
        "- - Oversampling: Balances classes using RandomOverSampler to mitigate bias toward the majority class (Hadrons).\n",
        "\n",
        "- **Train-Test Split**:\n",
        "\n",
        "- - 60% training, 20% validation, 20% test (shuffled)."
      ],
      "metadata": {
        "id": "Dd9_cInL4Omj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preparation\n",
        "def prepare_data(df, oversample=False):\n",
        "    X = df[cols[:-1]].values\n",
        "    y = df[cols[-1]].values\n",
        "    X = StandardScaler().fit_transform(X)  # Standardize features\n",
        "    if oversample:\n",
        "        from imblearn.over_sampling import RandomOverSampler\n",
        "        X, y = RandomOverSampler().fit_resample(X, y)\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "iyVW3WKO26hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "train, valid, test = np.split(df.sample(frac=1), [int(0.6*len(df)), int(0.8*len(df))])\n",
        "X_train, y_train = prepare_data(train, oversample=True)  # Balance classes\n",
        "X_test, y_test = prepare_data(test)"
      ],
      "metadata": {
        "id": "Q43s6EsG28kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Training and Evaluation**\n",
        "\n",
        "- **Model Initialization**:\n",
        " - lr = LogisticRegression()  # Default: L2 regularization\n",
        "\n",
        "- **Training**:\n",
        " - lr.fit(X_train, y_train)  # Learns coefficients (weights) via optimization\n",
        "\n",
        "- **Prediction & Evaluation**:\n",
        " - y_pred = lr.predict(X_test)\n",
        " - print(classification_report(y_test, y_pred))\n",
        "\n",
        "Reports precision, recall, F1-score, and accuracy."
      ],
      "metadata": {
        "id": "Pxhsj4mp452o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Evaluate Logistic Regression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "uNatZzcY2-Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Coefficients Analysis**\n",
        "\n",
        "- **Feature Importance**:\n",
        " - plt.bar(cols[:-1], lr.coef_[0])  # Plot coefficients\n",
        " - Positive weights: Increase the probability of class 1 (Gamma).\n",
        " - Negative weights: Decrease the probability of class 1."
      ],
      "metadata": {
        "id": "ra54Yf8F5kzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Coefficients Analysis\n",
        "plt.bar(cols[:-1], lr.coef_[0])  # Feature importance"
      ],
      "metadata": {
        "id": "KNulBxdy3FpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Decision Boundary Visualization (2D PCA)**\n",
        "\n",
        "- **PCA Reduction**: Projects features onto 2 principal components for plotting.\n",
        "\n",
        "- **Meshgrid Prediction**: Generates a grid of points and predicts their class using the trained model.\n",
        "\n",
        "- **Plot**:\n",
        "\n",
        "- - plt.contourf(xx, yy, Z, alpha=0.3)  # Decision boundary\n",
        "- - plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train)  # Data points\n",
        "\n",
        "Shows how the linear boundary separates classes in reduced space."
      ],
      "metadata": {
        "id": "lKgpN3iK57i5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Decision Boundary (2D PCA Projection)\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# Step 1: Reduce features to 2D using PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Step 2: Retrain KNN on 2D data (for visualization)\n",
        "#knn_pca = KNeighborsClassifier(n_neighbors=5)\n",
        "#knn_pca.fit(X_train_pca, y_train)\n",
        "model_pca = LogisticRegression().fit(X_train_pca, y_train)\n",
        "\n",
        "# Step 3: Create a meshgrid for decision boundary\n",
        "x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
        "y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                     np.arange(y_min, y_max, 0.02))\n",
        "Z = model_pca.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Step 4: Plot decision boundary and data points\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Paired)\n",
        "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train,\n",
        "            edgecolor='k', s=50, cmap=plt.cm.Paired)\n",
        "plt.title(\"Logistic Regression Decision Boundary (PCA-Reduced Data)\")\n",
        "plt.xlabel(\"Principal Component 1\")\n",
        "plt.ylabel(\"Principal Component 2\")\n",
        "plt.colorbar(label=\"Class (0=Hadron, 1=Gamma)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1bhdA6Ey3RXI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}